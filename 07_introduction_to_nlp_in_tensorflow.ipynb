{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_introduction_to_nlp_in_tensorflow.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMZRDZgsvADfBERGiPddmPe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pacifier25/ZTM-Tensorflow-course/blob/main/07_introduction_to_nlp_in_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pvC_w7Z3I7n"
      },
      "source": [
        "# Introduction Natural Language Processing Basics in TensorFlow\n",
        "\n",
        "NLP has the goal of deriving information out of natural language(could be text or speech)\n",
        "\n",
        "Another common term of NLP problems is sequence to sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e9d-mlCkJIQ",
        "outputId": "d634e981-c230-4232-b89b-547a4cf69f44"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri May 28 11:02:39 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scWXgTHf4vQe"
      },
      "source": [
        "# Get helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpBXyJWt4k2E",
        "outputId": "18f7d5bb-904a-4456-c003-060e9c89c052"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/Pacifier25/ZTM-Tensorflow-course/main/helper_function/helper.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-28 11:02:39--  https://raw.githubusercontent.com/Pacifier25/ZTM-Tensorflow-course/main/helper_function/helper.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10510 (10K) [text/plain]\n",
            "Saving to: ‘helper.py’\n",
            "\n",
            "helper.py           100%[===================>]  10.26K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-28 11:02:39 (112 MB/s) - ‘helper.py’ saved [10510/10510]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1dUkOia5cpv"
      },
      "source": [
        "# Import series of helper functions for the notebook\n",
        "from helper import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67W6cnef5rIV"
      },
      "source": [
        "## Get a text dataset \n",
        "\n",
        "The data set we are going to use is Kaggle introduction to NLP dataset(text sample to tweets labelled as disaster or non disaster).\n",
        "\n",
        "Here is the data:https://www.kaggle.com/c/nlp-getting-started/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56cFkBas5h-g",
        "outputId": "9d3aa396-c274-482d-b4d7-5386b62ea3f7"
      },
      "source": [
        "# Download data (same as from Kaggle)\n",
        "!wget  \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
        "\n",
        "# Unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-28 11:02:41--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.141.128, 2607:f8b0:4023:c03::80, 2607:f8b0:4023:c06::80, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2021-05-28 11:02:41 (112 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9oNgCE_7Of7"
      },
      "source": [
        "# Visualizing a text dataset\n",
        "\n",
        "To visualize our text sample we first have to read them in one way to do so is https://realpython.com/read-write-files-python/\n",
        "\n",
        "But i get to get visual straight away\n",
        "\n",
        "so another way to do se is to use pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "s6pvJ3hM6UN1",
        "outputId": "c4d3161d-e1d4-4a38-f363-9f6b058c7d07"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AIYv11oI9RY7",
        "outputId": "d2a95b64-4e58-4e82-8e86-e4484b56333f"
      },
      "source": [
        "train_df[\"text\"][1]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Forest fire near La Ronge Sask. Canada'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "dqcScON29WuB",
        "outputId": "9dea1f7a-5d08-4784-f395-3645ca4a638e"
      },
      "source": [
        "\n",
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac = 1,random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "nWLX_MKi-CFO",
        "outputId": "ccadacd8-61a6-4423-a8ae-3cacad36822f"
      },
      "source": [
        "# The test data doesn't have a target (that's what we'd try to predict)\n",
        "test_df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA9XJ3Fi-Kj2",
        "outputId": "544c1b6a-09ca-4a1c-c9ee-4f932ebc8a75"
      },
      "source": [
        "# How many examples of each class?\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2ZBJKxq-PgS",
        "outputId": "abd1e184-ed64-427e-b04b-34c0b8bfb24f"
      },
      "source": [
        "# How many samples total?\n",
        "print(f\"Total training samples: {len(train_df)}\")\n",
        "print(f\"Total test samples: {len(test_df)}\")\n",
        "print(f\"Total samples: {len(train_df) + len(test_df)}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total training samples: 7613\n",
            "Total test samples: 3263\n",
            "Total samples: 10876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slngjEx1-Y23",
        "outputId": "db761943-a9e1-4fc4-b401-9dff9d9b8458"
      },
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "\n",
        "random_index = random.randint(0,len(train_df)) # create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled [[\"text\",\"target\"]][random_index:random_index+5].itertuples():\n",
        "  _,text,target = row\n",
        "  print(f\"target: {target}\",\"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target: 0 (not real disaster)\n",
            "Text:\n",
            "Former Township fire truck being used in Philippines - Langley Times http://t.co/iMiLsFxntf #filipino\n",
            "\n",
            "---\n",
            "\n",
            "target: 0 (not real disaster)\n",
            "Text:\n",
            "'Hey bitch blow me' uh no. Stick your dick in some water then an outlet so u get electrocuted..\n",
            "\n",
            "---\n",
            "\n",
            "target: 1 (real disaster)\n",
            "Text:\n",
            "Looks like a perfect storm-free evening coming up.  Check out the outdoor happenings featured at http://t.co/hUzrHgmkSY #EventsPalmBeach.\n",
            "\n",
            "---\n",
            "\n",
            "target: 0 (not real disaster)\n",
            "Text:\n",
            "Rick and Morty - They Blew Up : http://t.co/UQKX5VbiuM\n",
            "\n",
            "---\n",
            "\n",
            "target: 0 (not real disaster)\n",
            "Text:\n",
            "I've been meaning to harm you in the best way I see fit??\n",
            "\n",
            "---\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW5jP76hBXIQ"
      },
      "source": [
        "# Split data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCtq4pWCBDGn"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentence,val_sentence,train_label,val_label = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                     train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                     test_size = 0.1,# dedicate 10% of samples to validation set\n",
        "                                                                     random_state = 42)# random state for reproducibility"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdTEe5OmDGv0",
        "outputId": "8002fa28-c2af-4dba-9eb6-6daabb34ebd8"
      },
      "source": [
        "# Check the lengths\n",
        "len(train_sentence), len(train_label), len(val_sentence), len(val_label)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDc0OJnGDSHC",
        "outputId": "0de1b880-4978-4ab5-9bf6-24a1d2d00dfb"
      },
      "source": [
        "# View the first 10 training sentences and their labels\n",
        "train_sentence[:10], train_label[:10]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI0GGy1SEET7"
      },
      "source": [
        "# Converting text into numbers\n",
        "\n",
        "When dealing with text problem one of the first thing you'll have to do before you can build a model is to convert your text to answer\n",
        "\n",
        "There are few ways to build this:\n",
        "\n",
        "1. Tokenization - direct mapping of token(a token could be a word or a character) to a number\n",
        "\n",
        "2. Embedding - Create a matrix of feature vector for each token(the size of the feature vector can be defined and this embedding can be learned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLqDJxdkF2c8"
      },
      "source": [
        "## Text vectorization (tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHKTh_InDZE8",
        "outputId": "51a3e9c5-5139-49b4-ffab-90f2475872cf"
      },
      "source": [
        "train_sentence[:5]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXhyP_mvF7_L"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "text_vectorization = TextVectorization(max_tokens = None, # how many words in the vocabulary (all of the different words in your text)\n",
        "                                       standardize = \"lower_and_strip_punctuation\", # how to process text\n",
        "                                       split = \"whitespace\",# how to split tokens\n",
        "                                       ngrams = None, # create groups of n-words?\n",
        "                                       output_mode = \"int\", # how to map tokens to numbers\n",
        "                                       output_sequence_length = None, # how long should the output sequence of tokens be?\n",
        "                                       pad_to_max_tokens = True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ig06StGHPu6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c06b97-580e-43c3-c0d1-64b42b9508b4"
      },
      "source": [
        "# Find average number of tokens (words) in training Tweets\n",
        "round(sum([len(i.split())for i in train_sentence])/ len(train_sentence))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJNZ9_gmSMjp"
      },
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSMvGPcpS3DO"
      },
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentence)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X1yl9bfhJ5i",
        "outputId": "f593b0d7-933e-4561-8b4c-b0dfe567da90"
      },
      "source": [
        "# Create sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my city\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 182,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrFwCP9LhcCK",
        "outputId": "e487b039-5ade-4732-b0a5-53c5554724b9"
      },
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentence)\n",
        "print(f\"Original text:\\n{random_sentence}\\n\\n Vectorized version :\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:\n",
            "320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/M4JDZMGJoW | @djicemoon | #Dubstep #TrapMusic #DnB #EDM #Dance #IcesÛ_ http://t.co/n0uhAsfkBv\n",
            "\n",
            " Vectorized version :\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[2582, 2420, 2428,  966,    1, 2490, 2133, 2249, 2138, 1685, 1307,\n",
              "        2427,    1,    0,    0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUPRtC_uiICk",
        "outputId": "dff279c8-507a-40a1-ea83-a833b93d0f2e"
      },
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
        "bottom_5_words = words_in_vocab[-5:]# least common tokens\n",
        "print(f\"Number of words in vocab:{len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words : {top_5_words}\")\n",
        "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in vocab:10000\n",
            "Top 5 most common words : ['', '[UNK]', 'the', 'a', 'in']\n",
            "Bottom 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFq1NcvgFJ0Q"
      },
      "source": [
        "# Creating an Embedding using an Embedding Layer\n",
        "\n",
        "To make our embedding we are going to use tensorflow embedding's layers\n",
        "\n",
        "The main parameters we're concerned about here are:\n",
        "\n",
        "* **input_dim** - The size of the vocabulary (e.g. len(text_vectorizer.get_vocabulary()).\n",
        "* **output_dim** - The size of the output embedding vector, for example, a value of 100 outputs a feature vector of size 100 for each word.\n",
        "embeddings_initializer - How to initialize the embeddings matrix, default is \"uniform\" which randomly initalizes embedding matrix with uniform distribution. This can be changed for using pre-learned embeddings.\n",
        "* **input_length** - Length of sequences being passed to embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYaGayfql6nd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67a6a335-789b-4152-a842-3a76a204fed2"
      },
      "source": [
        "embedding = tf.keras.layers.Embedding(input_dim = max_vocab_length,# set input shape\n",
        "                                      output_dim = 128,# set size of embedding vector\n",
        "                                      embeddings_initializer = \"uniform\", # default, intialize randomly\n",
        "                                      input_length = max_length)# how long is each input\n",
        "embedding"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7fb580403b50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xMZEI9xG_vP",
        "outputId": "9a55f556-45db-4896-a940-c9886477ba82"
      },
      "source": [
        "# Get a random sentence from training set\n",
        "random_sentence = random.choice(train_sentence)\n",
        "print(f\"Original text:\\n {random_sentence}\\n\\n Embedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into numerical representation)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:\n",
            " Alhaji Putin is far from being a good person sha. At least I had front row seat to his complete obliteration of Ibeto cement a competitor.\n",
            "\n",
            " Embedded version:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.0321216 , -0.01617037,  0.013471  , ...,  0.04952255,\n",
              "          0.02768001, -0.04662972],\n",
              "        [-0.03936365, -0.01575228,  0.02051998, ...,  0.03571549,\n",
              "          0.01827404,  0.01894157],\n",
              "        [ 0.04327028,  0.04041355,  0.00631315, ...,  0.04916139,\n",
              "         -0.01485412, -0.03350045],\n",
              "        ...,\n",
              "        [ 0.01448599, -0.00990849, -0.01518555, ...,  0.04542223,\n",
              "          0.04412622, -0.04585706],\n",
              "        [-0.01084422, -0.03021554, -0.01043991, ...,  0.0223393 ,\n",
              "         -0.04170129, -0.03907288],\n",
              "        [-0.04032727,  0.02777326, -0.01860743, ..., -0.01478362,\n",
              "         -0.02034804,  0.01503788]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbKmRpCSH03w",
        "outputId": "e31b166e-ccdc-414c-9d82-58c87933bf6d"
      },
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([ 0.0321216 , -0.01617037,  0.013471  ,  0.03521544, -0.03382201,\n",
              "       -0.01228849,  0.04108198,  0.03392367, -0.00834386, -0.02504237,\n",
              "       -0.01899121,  0.02930398, -0.02103047, -0.03049849,  0.03241463,\n",
              "       -0.00655087,  0.01859364, -0.03772767,  0.00726143,  0.0015452 ,\n",
              "        0.00077871, -0.01065295, -0.01978164, -0.0135564 , -0.01873487,\n",
              "       -0.01322822, -0.04686267, -0.02613121, -0.01429467, -0.01174391,\n",
              "        0.04289973, -0.04692353,  0.01344571, -0.02172827,  0.03132811,\n",
              "        0.0368593 , -0.0060013 ,  0.00074791, -0.04026915, -0.02965154,\n",
              "       -0.03229355, -0.04189522,  0.01835338,  0.02737785,  0.03343629,\n",
              "        0.03000983,  0.04874646,  0.03970292, -0.02518453, -0.00337268,\n",
              "       -0.01974609, -0.02594532,  0.00850947, -0.04339113, -0.01937522,\n",
              "        0.01807928,  0.04397866, -0.02749074, -0.03889392, -0.01903341,\n",
              "       -0.04320177,  0.00351089,  0.04814209,  0.04148097, -0.00306989,\n",
              "        0.03856443,  0.00321621,  0.00329487, -0.04551046,  0.04604015,\n",
              "       -0.04257914,  0.0113593 ,  0.00678258,  0.03139571, -0.00077667,\n",
              "        0.01222756,  0.03709053, -0.04767491,  0.00897463, -0.01744536,\n",
              "       -0.02544401, -0.04087657,  0.04191828, -0.04612408,  0.03892902,\n",
              "       -0.02300012, -0.04075702,  0.01452612,  0.02664261,  0.03693367,\n",
              "        0.01596269,  0.01083064,  0.04802414,  0.03865929,  0.04973544,\n",
              "        0.01087042, -0.00874484,  0.02981429, -0.04322829, -0.00365089,\n",
              "        0.03021231, -0.03894087, -0.00854122, -0.02556315,  0.04004702,\n",
              "        0.00486173, -0.03170128,  0.04313114,  0.00605379,  0.00956647,\n",
              "       -0.02636237,  0.00254489,  0.04623554, -0.00240546,  0.00899844,\n",
              "        0.03748323, -0.02337825,  0.03686288,  0.00711877, -0.0099727 ,\n",
              "       -0.04495856, -0.01417406, -0.02590324,  0.01525462,  0.02378285,\n",
              "        0.04952255,  0.02768001, -0.04662972], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr1mN9OmINAB"
      },
      "source": [
        "# Modelling a text dataset(running a series of experiment)\n",
        "\n",
        "Now we have got a way to turn our text sequences into number, it's time to start building a series of modelling experiment\n",
        "\n",
        "* **Model 0**: Naive Bayes (baseline)\n",
        "* **Model 1**: Feed-forward neural network (dense model)\n",
        "* **Model 2**: LSTM model\n",
        "* **Model 3**: GRU model\n",
        "* **Model 4**: Bidirectional-LSTM model\n",
        "* **Model 5**: 1D Convolutional Neural Network\n",
        "* **Model 6**: TensorFlow Hub Pretrained Feature Extractor\n",
        "* **Model 7**: Same as model 6 with 10% of training data\n",
        "\n",
        "How we are going to approach all of these\n",
        "\n",
        "Each experiment will go through the following steps:\n",
        "\n",
        "* Construct the model\n",
        "* Train the model\n",
        "* Make predictions with the model\n",
        "* Track prediction evaluation metrics for later comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY1NM-xHKNFu"
      },
      "source": [
        "# Model 0: Getting a baseline\n",
        "\n",
        "As with all machine learning modelling experiments, it's important to create a baseline model so you've got a benchmark for future experiments to build upon.\n",
        "\n",
        "To create our baseline, we'll create a Scikit-Learn Pipeline using the TF-IDF (term frequency-inverse document frequency) formula to convert our words to numbers and then model them with the Multinomial Naive Bayes algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyEjh6QYH_vw",
        "outputId": "be9376c6-3463-4846-f183-56a72f8c396e"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\",TfidfVectorizer()),# convert words to numbers using tfidf\n",
        "                    (\"clf\",MultinomialNB()) # model the text\n",
        "])\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentence,train_label)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBbsV0VoLwaM",
        "outputId": "99922088-03af-439c-f5f5-f86f43752f87"
      },
      "source": [
        "baseline_score = model_0.score(val_sentence,val_label)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our baseline model achieves an accuracy of: 79.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhLOAPhkL7It",
        "outputId": "dd1f6049-663b-4f7a-f4a3-178731b96a45"
      },
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentence)\n",
        "baseline_preds[:10]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJDWSROYOQl8"
      },
      "source": [
        "## Creating an evaluation function for our model experiments\n",
        "\n",
        "We could evaluate these as they are but since we're going to be evaluating several models in the same way going forward, let's create a helper function which takes an array of predictions and ground truth labels and computes the following:\n",
        "\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H44BNSj4MQGW"
      },
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score,precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true,y_preds):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true,y_preds)*100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision,model_recall,model_f1, _ = precision_recall_fscore_support(y_true,y_preds,average = \"weighted\")\n",
        "  model_results = {\n",
        "      \"accuracy\":model_accuracy,\n",
        "      \"precision\":model_precision,\n",
        "       \"recall\":model_recall,\n",
        "       \"f1\":model_f1\n",
        "  }\n",
        "  return model_results"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8TXSbWHPtnP",
        "outputId": "c8108c50-dc71-4f46-eb3a-5d289d072428"
      },
      "source": [
        "# Get the baseline results\n",
        "baseline_results = calculate_results(y_true = val_label,\n",
        "                                     y_preds = baseline_preds)\n",
        "\n",
        "baseline_results"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WcBMN3DxJj0"
      },
      "source": [
        "# Model 1: A simple dense model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2ZzkWEBP_LQ"
      },
      "source": [
        "# Create tensorboard callback (need to create a new one for each model)\n",
        "from helper import create_tensorboard_callback\n",
        "\n",
        "# Create directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OXgSS3ixbul"
      },
      "source": [
        "# Create directory to save TensorBoard logs\n",
        "inputs = tf.keras.layers.Input(shape = (1,),dtype = \"string\") # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x) # create an embedding of the numerized numbers\n",
        "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "outputs = tf.keras.layers.Dense(1,activation=tf.keras.activations.sigmoid)(x)# create the output layer, want binary outputs so use sigmoid activation\n",
        "model_1 = tf.keras.Model(inputs,outputs,name = \"model_1_dense\")# construct the model"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI_wKTi4z6mP"
      },
      "source": [
        "# Compile model\n",
        "model_1.compile(loss = tf.keras.losses.binary_crossentropy,\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTbml4U80Q9z",
        "outputId": "87bfb833-3c9f-4017-e77d-e8744c5b5582"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_u35Xysi0XEE",
        "outputId": "606178d1-7250-4163-a301-b8054aaff096"
      },
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_sentence,\n",
        "                              train_label,\n",
        "                              epochs = 5,\n",
        "                              validation_data = (val_sentence,val_label),\n",
        "                              callbacks = [create_tensorboard_callback(dir_name = SAVE_DIR,\n",
        "                                                                       experiment_name = \"simple_dense_model\")])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20210528-110249\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 17ms/step - loss: 0.6137 - accuracy: 0.6904 - val_loss: 0.5345 - val_accuracy: 0.7612\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.4424 - accuracy: 0.8170 - val_loss: 0.4694 - val_accuracy: 0.7874\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.3469 - accuracy: 0.8610 - val_loss: 0.4581 - val_accuracy: 0.7835\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.2845 - accuracy: 0.8883 - val_loss: 0.4632 - val_accuracy: 0.7848\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.2374 - accuracy: 0.9117 - val_loss: 0.4792 - val_accuracy: 0.7769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOUhQtF31CNF",
        "outputId": "f0891a01-2fe7-42af-865c-4fcd402cb9f7"
      },
      "source": [
        "# Check the model result\n",
        "model_1.evaluate(val_sentence,val_label)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.7769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4791974127292633, 0.7769029140472412]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hge9Uuwc30iS"
      },
      "source": [
        "model_1_preds = model_1.predict(val_sentence)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMSNa8rG4Vik"
      },
      "source": [
        "model_1_pred_prob = tf.squeeze(tf.round(model_1_preds))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gn811BhJ3kS6",
        "outputId": "d4e05fb4-0f8b-4c56-d425-830b50f638a1"
      },
      "source": [
        "model_1_results = calculate_results(y_true = val_label,\n",
        "                                    y_preds = model_1_pred_prob)\n",
        "model_1_results"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.69028871391076,\n",
              " 'f1': 0.7751243211017478,\n",
              " 'precision': 0.7781874595396938,\n",
              " 'recall': 0.7769028871391076}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR-SiGu47JPS"
      },
      "source": [
        "# Visualizing learned embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2wt2yOp3_6h",
        "outputId": "992e4765-1687-43d7-836b-3e8835b88b93"
      },
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab),words_in_vocab[:10]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2osHank9NVD",
        "outputId": "bef4851d-0874-43ee-e7f3-44bd038eb126"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaCIMlKC9QiW",
        "outputId": "a690e846-faac-4adf-8d1b-e6004f75322b"
      },
      "source": [
        "# Get the weight matrix of embedding layer \n",
        "# (these are the numerical patterns between the text in the training dataset the model has learned)\n",
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "print(embed_weights.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPOpTAXs9Y-2"
      },
      "source": [
        "import io\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6qzCF3899H4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "34bbe32e-73b5-43af-bd47-8b9d2726ac58"
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vectors.tsv')\n",
        "  files.download('metadata.tsv')\n",
        "except Exception:\n",
        "  pass\n",
        "  "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_77772ef2-2252-4fc5-817a-4a8f89a78497\", \"vectors.tsv\", 15366713)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7124a183-ecc1-465f-bbdd-fc137f49923d\", \"metadata.tsv\", 80388)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz8vsLhQAZNL"
      },
      "source": [
        "1. Go to http://projector.tensorflow.org/\n",
        "2. Click on \"Load data\"\n",
        "3. Upload the two files you downloaded (embedding_vectors.tsv and embedding_metadata.tsv)\n",
        "4. Explore\n",
        "5. Optional: You can share the data you've created by clicking \"Publish\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CcAIRIlBuPn"
      },
      "source": [
        "# Recurrent Neural Networks (RNN's)\n",
        "\n",
        "RNN's is useful for sequence data\n",
        "\n",
        "The premise of recurent neural network is to use the representation of previous input to aid the representation of later output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfjHCNs5Di4A"
      },
      "source": [
        "## Model 2: LSTM\n",
        "\n",
        "LSTM = long short term memory(one of the most popular LSTM cell)\n",
        "\n",
        "Our structure of RNN typically looks like this\n",
        "\n",
        "`Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwsdozFx_Ske",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f2d744d-2874-4bbe-a378-fc5b2ad58577"
      },
      "source": [
        "# Create LSTM model\n",
        "from tensorflow.keras import layers\n",
        "inputs = tf.keras.layers.Input(shape = (1,),dtype = \"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(x.shape)\n",
        "# x = tf.keras.layers.LSTM(64,return_sequences=True)(x)  # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True)\n",
        "x  = tf.keras.layers.LSTM(64)(x) # return vector for whole sequence\n",
        "print(x.shape)\n",
        "# x = tf.keras.layers.Dense(64,activation = tf.keras.activations.relu)(x)\n",
        "outputs = tf.keras.layers.Dense(1,activation = \"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs,outputs,name =\"model_2_LSTM\")\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 15, 128)\n",
            "(None, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQoXp5_zHZjT"
      },
      "source": [
        "model_2.compile(loss = tf.keras.losses.binary_crossentropy,\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTYA9P2KHrE9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e51275-cc37-4047-9fc2-dffa3895e05d"
      },
      "source": [
        "model_2_history = model_2.fit(train_sentence,\n",
        "                              train_label,\n",
        "                              epochs = 5,\n",
        "                              validation_data = (val_sentence,val_label),\n",
        "                              callbacks = [create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                       \"LSTM\")])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/LSTM/20210528-110538\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 9s 21ms/step - loss: 0.2221 - accuracy: 0.9238 - val_loss: 0.5720 - val_accuracy: 0.7848\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.1567 - accuracy: 0.9432 - val_loss: 0.6299 - val_accuracy: 0.7795\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.1252 - accuracy: 0.9531 - val_loss: 0.7935 - val_accuracy: 0.7795\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.1070 - accuracy: 0.9574 - val_loss: 0.8478 - val_accuracy: 0.7795\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0825 - accuracy: 0.9704 - val_loss: 1.0090 - val_accuracy: 0.7690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTr095dNGZQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6b80ecd-d717-4327-f305-f2dca48290ca"
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZJxJ6bjG8A5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0b6f100-1d1b-46ef-99b8-296e44fb7ee9"
      },
      "source": [
        "# Make predictions on the validation dataset\n",
        "model_2_pred_probs = model_2.predict(val_sentence)\n",
        "model_2_pred_probs.shape,model_2_pred_probs[:10]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1), array([[4.3194368e-03],\n",
              "        [8.2260782e-01],\n",
              "        [9.9976772e-01],\n",
              "        [7.0212901e-02],\n",
              "        [4.8676159e-04],\n",
              "        [9.9903631e-01],\n",
              "        [6.4431357e-01],\n",
              "        [9.9984741e-01],\n",
              "        [9.9972683e-01],\n",
              "        [5.4219866e-01]], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DO_DiWDIfkF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc7e92b6-8952-4fec-a31d-5196eb48be6d"
      },
      "source": [
        "# Round out predictions and reduce to 1-dimensional array\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oceVqLvIis_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e45885ea-de0c-44d3-8e2f-1c6c054b379f"
      },
      "source": [
        "# Calculate LSTM model results\n",
        "model_2_results = calculate_results(y_true=val_label,\n",
        "                                    y_preds=model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.9028871391076,\n",
              " 'f1': 0.766385677090764,\n",
              " 'precision': 0.7717390408616506,\n",
              " 'recall': 0.7690288713910761}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlbSsaNXInID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f54530ba-6874-49c6-ec4e-84e59696d6e2"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b60SQrxdUlUg"
      },
      "source": [
        "# Model 3: GRU\n",
        "\n",
        "Another popular and effective RNN component is the GRU or gated recurrent unit.\n",
        "\n",
        "The GRU cell has similar features to an LSTM cell but has less parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvvqjAy0Ujon"
      },
      "source": [
        "# Build an RNN using the GRU cell\n",
        "inputs = tf.keras.layers.Input(shape = (1,),dtype = \"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.GRU(64, return_sequences=True) # stacking recurrent cells requires return_sequences=True\n",
        "x = tf.keras.layers.GRU(64)(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer after GRU cell\n",
        "outputs = tf.keras.layers.Dense(1,activation=tf.keras.activations.sigmoid)(x)\n",
        "model_3 = tf.keras.Model(inputs,outputs,name = \"model_3_GRU\")\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MssFgd3PW_48"
      },
      "source": [
        "model_3.compile(loss = tf.keras.losses.binary_crossentropy,\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZXUgcwMIvJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19c9ffd7-17c9-46fd-da5b-d92ab49c15ac"
      },
      "source": [
        "model_3.summary()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 64)                37248     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrQ98f-7W3Eg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feff6f00-3bb4-4f94-b37c-2fe364438a98"
      },
      "source": [
        "# Fit model\n",
        "model_3_history = model_3.fit(train_sentence,\n",
        "                              train_label,\n",
        "                              epochs =5,\n",
        "                              validation_data = (val_sentence,val_label),\n",
        "                              callbacks = [create_tensorboard_callback(dir_name = SAVE_DIR,\n",
        "                                                                       experiment_name = \"GRU\")])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/GRU/20210528-110602\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 19ms/step - loss: 0.1640 - accuracy: 0.9355 - val_loss: 0.6819 - val_accuracy: 0.7769\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0867 - accuracy: 0.9688 - val_loss: 0.8439 - val_accuracy: 0.7782\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0731 - accuracy: 0.9714 - val_loss: 1.0344 - val_accuracy: 0.7795\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0584 - accuracy: 0.9755 - val_loss: 1.1040 - val_accuracy: 0.7572\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0593 - accuracy: 0.9753 - val_loss: 1.1702 - val_accuracy: 0.7782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_-cy29eYMIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b95495a-884c-4f4e-a34a-47841999e4a9"
      },
      "source": [
        "# Make predictions on the validation data\n",
        "model_3_pred_probs = model_3.predict(val_sentence)\n",
        "model_3_pred_probs.shape,model_3_pred_probs[:10]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1), array([[1.2900339e-03],\n",
              "        [7.6996857e-01],\n",
              "        [9.9969935e-01],\n",
              "        [8.5849516e-02],\n",
              "        [5.6807334e-05],\n",
              "        [9.9733222e-01],\n",
              "        [3.8718441e-01],\n",
              "        [9.9985445e-01],\n",
              "        [9.9979216e-01],\n",
              "        [9.3607241e-01]], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvb0ya91YjWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d44b35fb-367a-450a-cb54-8a1c5af036c1"
      },
      "source": [
        "# Convert prediction probabilities to prediction classes\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 0., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL2ZNyfeYmlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77345166-eee2-4256-d6e0-cc93f1def42c"
      },
      "source": [
        "# Calcuate model_3 results\n",
        "model_3_results = calculate_results(y_true = val_label,\n",
        "                                    y_preds = model_3_preds)\n",
        "model_3_results"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.82152230971128,\n",
              " 'f1': 0.7758810170952618,\n",
              " 'precision': 0.7807522349051432,\n",
              " 'recall': 0.7782152230971129}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51cf-XnAZLZe"
      },
      "source": [
        "# Model 4: Bidirectonal RNN model\n",
        "\n",
        "Normal RNN goes from left to right(just like you read an english sentence) however a bidirectional RNN goes from right to left as well as left to right"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2TOspc7Y016"
      },
      "source": [
        "# Build a Bidirectional RNN in TensorFlow\n",
        "inputs = tf.keras.layers.Input(shape = (1,),dtype = \"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # stacking RNN layers requires return_sequences=True\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))(x)\n",
        "outputs = tf.keras.layers.Dense(1,activation = tf.keras.activations.sigmoid)(x)\n",
        "model_4 = tf.keras.Model(inputs,outputs,name = \"model_4_bidirectional\")\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ER9lHBaazCs"
      },
      "source": [
        "🔑 **Note**: You can use the Bidirectional wrapper on any RNN cell in TensorFlow. For example, layers.Bidirectional(layers.GRU(64)) creates a bidirectional GRU cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA7moITFasX0"
      },
      "source": [
        "# Compile\n",
        "model_4.compile(loss = tf.keras.losses.binary_crossentropy,\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg8mykUKbDNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9e45bd0-e5e6-4f40-8bc6-19c2671377b9"
      },
      "source": [
        "model_4.summary()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3-v85SebFpc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b1d9570-58fc-4fb1-fc93-31ab476ef415"
      },
      "source": [
        "# Fit the model (takes longer because of the bidirectional layers)\n",
        "model_4_history = model_4.fit(train_sentence,\n",
        "                              train_label,\n",
        "                              epochs = 5,\n",
        "                              validation_data = (val_sentence,val_label),\n",
        "                              callbacks = [create_tensorboard_callback(dir_name = SAVE_DIR,\n",
        "                                                                       experiment_name = \"bidirectional_RNN\")])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/bidirectional_RNN/20210528-110626\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 24ms/step - loss: 0.1085 - accuracy: 0.9653 - val_loss: 0.9088 - val_accuracy: 0.7743\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0525 - accuracy: 0.9756 - val_loss: 1.3342 - val_accuracy: 0.7743\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0468 - accuracy: 0.9793 - val_loss: 1.3535 - val_accuracy: 0.7690\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0456 - accuracy: 0.9797 - val_loss: 1.1790 - val_accuracy: 0.7664\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0410 - accuracy: 0.9799 - val_loss: 1.3545 - val_accuracy: 0.7743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtr_VuPXbo4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e1a61c4-7a5a-436a-9e64-958a3132251a"
      },
      "source": [
        "# Make predictions with bidirectional RNN on the validation data\n",
        "model_4_pred_probs = model_4.predict(val_sentence)\n",
        "model_4_pred_probs[:10]"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.1518551e-03],\n",
              "       [8.7457448e-01],\n",
              "       [9.9996305e-01],\n",
              "       [2.4180806e-01],\n",
              "       [3.4741068e-05],\n",
              "       [9.9975175e-01],\n",
              "       [5.5741405e-01],\n",
              "       [9.9998820e-01],\n",
              "       [9.9996603e-01],\n",
              "       [9.9861658e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4zQxDX0b4Bx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "592f6cae-04ea-4d9e-d97b-92ccce6cbb70"
      },
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAyS7PIob7ps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28f7fbba-48c8-442c-9ced-e90e67fe6ee7"
      },
      "source": [
        "# Calculate bidirectional RNN model results\n",
        "model_4_results = calculate_results(val_label,model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.42782152230971,\n",
              " 'f1': 0.7715524459329461,\n",
              " 'precision': 0.7775061562364454,\n",
              " 'recall': 0.7742782152230971}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1XgOEyhcO9x"
      },
      "source": [
        "# Convolutional Neural Networks for Text\n",
        "\n",
        "We have used CNN's for images but images are typically 2D(height x width)... however our data is 1D\n",
        "\n",
        "Previously we have used Conv2D for our images data but now we are going to use Conv1D \n",
        "\n",
        "The typical structure of Conv1D model sequence(in our case,text)\n",
        "\n",
        "A typical CNN architecture for sequences will look like the following:\n",
        "\n",
        "```\n",
        "Inputs (text) -> Tokenization -> Embedding -> Layers -> Outputs (class probabilities)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaNT0Xc0dWOP"
      },
      "source": [
        "### Model 5: Conv1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WW6gVO-0cKR2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f5cb3cf-ad55-4009-80b5-b40393052b28"
      },
      "source": [
        "# Test out the embedding, 1D convolutional and max pooling\n",
        "embedding_test = embedding(text_vectorizer([\"This is a test sentence\"]))# turn target sentence into embedding\n",
        "conv_1d = tf.keras.layers.Conv1D(filters = 32,\n",
        "                                kernel_size = 5,# convolve over target sequence 5 words at a time\n",
        "                                activation = tf.keras.activations.relu) \n",
        "conv_1d_output = conv_1d(embedding_test) # pass embedding through 1D convolutional layer\n",
        "max_pool = tf.keras.layers.GlobalMaxPool1D()\n",
        "max_pool_output = max_pool(conv_1d_output)# get the most important features\n",
        "embedding_test.shape,conv_1d_output.shape,max_pool_output.shape\n",
        "\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D02FIOLOeu-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6a4e9cc-e760-43a2-f874-58c64cf84a24"
      },
      "source": [
        "# See the outputs of each layer\n",
        "embedding_test[:1], conv_1d_output[:1], max_pool_output[:1]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              " array([[[ 0.00610069, -0.014148  , -0.03577311, ..., -0.01596391,\n",
              "          -0.00522874, -0.04137798],\n",
              "         [ 0.05776696,  0.07461418, -0.01750338, ...,  0.08424553,\n",
              "          -0.03892394,  0.00521239],\n",
              "         [ 0.04639052,  0.04746436,  0.0051148 , ...,  0.01400761,\n",
              "           0.04432344,  0.02499054],\n",
              "         ...,\n",
              "         [ 0.04260996,  0.0105852 , -0.0022139 , ...,  0.00873823,\n",
              "          -0.02004847,  0.00037022],\n",
              "         [ 0.04260996,  0.0105852 , -0.0022139 , ...,  0.00873823,\n",
              "          -0.02004847,  0.00037022],\n",
              "         [ 0.04260996,  0.0105852 , -0.0022139 , ...,  0.00873823,\n",
              "          -0.02004847,  0.00037022]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=\n",
              " array([[[2.8374441e-02, 0.0000000e+00, 4.3775730e-02, 1.0628202e-02,\n",
              "          9.0518102e-02, 2.3776313e-02, 4.1118748e-02, 0.0000000e+00,\n",
              "          0.0000000e+00, 2.9288713e-02, 0.0000000e+00, 0.0000000e+00,\n",
              "          1.9924141e-02, 1.4033529e-02, 6.6014960e-02, 0.0000000e+00,\n",
              "          4.2152952e-04, 6.5285906e-02, 0.0000000e+00, 0.0000000e+00,\n",
              "          2.5680970e-02, 3.0528184e-02, 0.0000000e+00, 0.0000000e+00,\n",
              "          5.8232509e-02, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "          0.0000000e+00, 0.0000000e+00, 2.0185623e-02, 0.0000000e+00],\n",
              "         [0.0000000e+00, 6.2095970e-03, 9.0187371e-02, 7.0904680e-02,\n",
              "          0.0000000e+00, 7.4885949e-02, 1.7859343e-02, 3.1489640e-02,\n",
              "          7.0383593e-02, 8.8874325e-02, 3.6939375e-02, 1.4376573e-02,\n",
              "          0.0000000e+00, 0.0000000e+00, 1.4534174e-03, 0.0000000e+00,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "          6.3272595e-02, 5.1980525e-02, 0.0000000e+00, 0.0000000e+00,\n",
              "          0.0000000e+00, 1.2395434e-01, 6.1277986e-02, 1.0912762e-04,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.4447728e-02],\n",
              "         [9.4284758e-02, 0.0000000e+00, 0.0000000e+00, 1.3475132e-03,\n",
              "          7.9039812e-02, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "          6.1897535e-02, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "          2.0785056e-02, 2.5533041e-02, 2.6464920e-02, 0.0000000e+00,\n",
              "          1.7245311e-02, 0.0000000e+00, 0.0000000e+00, 2.8011493e-02,\n",
              "          0.0000000e+00, 6.1335213e-02, 0.0000000e+00, 5.2323021e-02,\n",
              "          0.0000000e+00, 7.2689429e-02, 0.0000000e+00, 0.0000000e+00,\n",
              "          0.0000000e+00, 0.0000000e+00, 1.9583503e-02, 6.9651470e-02],\n",
              "         [4.7793165e-02, 0.0000000e+00, 3.3128742e-02, 2.7864413e-02,\n",
              "          5.3542480e-02, 1.2590269e-02, 0.0000000e+00, 1.3821160e-02,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.7046859e-02,\n",
              "          6.0011065e-03, 3.6540963e-03, 2.0973232e-02, 1.3065733e-02,\n",
              "          4.3293811e-02, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "          0.0000000e+00, 3.0193297e-02, 3.4238696e-02, 2.2900863e-02,\n",
              "          0.0000000e+00, 3.3347681e-02, 0.0000000e+00, 1.3783334e-02,\n",
              "          0.0000000e+00, 0.0000000e+00, 2.8188623e-02, 4.5987617e-02],\n",
              "         [7.4965745e-02, 0.0000000e+00, 0.0000000e+00, 2.6870625e-02,\n",
              "          1.7455658e-02, 0.0000000e+00, 2.4903659e-03, 0.0000000e+00,\n",
              "          0.0000000e+00, 8.2561765e-03, 6.0180668e-03, 4.6669565e-02,\n",
              "          0.0000000e+00, 0.0000000e+00, 3.3371978e-02, 1.9298082e-03,\n",
              "          3.4510277e-02, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "          5.3661279e-02, 0.0000000e+00, 3.1154348e-02, 0.0000000e+00,\n",
              "          0.0000000e+00, 2.1315016e-02, 9.4314143e-03, 0.0000000e+00,\n",
              "          0.0000000e+00, 0.0000000e+00, 1.8032504e-02, 8.7302163e-02],\n",
              "         [3.3474065e-02, 0.0000000e+00, 0.0000000e+00, 2.3239497e-02,\n",
              "          1.3901936e-02, 2.0851742e-02, 0.0000000e+00, 0.0000000e+00,\n",
              "          7.6191919e-03, 1.6248614e-02, 0.0000000e+00, 4.7639787e-02,\n",
              "          0.0000000e+00, 0.0000000e+00, 2.6531793e-02, 1.8276531e-02,\n",
              "          4.3799125e-02, 0.0000000e+00, 0.0000000e+00, 2.3779022e-03,\n",
              "          2.2480682e-02, 1.0863055e-02, 4.2251475e-02, 3.6259666e-03,\n",
              "          0.0000000e+00, 1.8738218e-02, 3.4544591e-02, 0.0000000e+00,\n",
              "          3.3347484e-02, 0.0000000e+00, 4.0786181e-02, 4.7010679e-02],\n",
              "         [3.3474065e-02, 0.0000000e+00, 0.0000000e+00, 2.3239497e-02,\n",
              "          1.3901931e-02, 2.0851737e-02, 0.0000000e+00, 0.0000000e+00,\n",
              "          7.6191872e-03, 1.6248610e-02, 0.0000000e+00, 4.7639798e-02,\n",
              "          0.0000000e+00, 0.0000000e+00, 2.6531799e-02, 1.8276535e-02,\n",
              "          4.3799125e-02, 0.0000000e+00, 0.0000000e+00, 2.3779080e-03,\n",
              "          2.2480682e-02, 1.0863047e-02, 4.2251471e-02, 3.6259699e-03,\n",
              "          0.0000000e+00, 1.8738218e-02, 3.4544583e-02, 0.0000000e+00,\n",
              "          3.3347495e-02, 0.0000000e+00, 4.0786192e-02, 4.7010675e-02],\n",
              "         [3.3474073e-02, 0.0000000e+00, 0.0000000e+00, 2.3239490e-02,\n",
              "          1.3901935e-02, 2.0851739e-02, 0.0000000e+00, 0.0000000e+00,\n",
              "          7.6191882e-03, 1.6248606e-02, 0.0000000e+00, 4.7639791e-02,\n",
              "          0.0000000e+00, 0.0000000e+00, 2.6531801e-02, 1.8276535e-02,\n",
              "          4.3799132e-02, 0.0000000e+00, 0.0000000e+00, 2.3779077e-03,\n",
              "          2.2480676e-02, 1.0863046e-02, 4.2251475e-02, 3.6259796e-03,\n",
              "          0.0000000e+00, 1.8738205e-02, 3.4544576e-02, 0.0000000e+00,\n",
              "          3.3347502e-02, 0.0000000e+00, 4.0786177e-02, 4.7010675e-02],\n",
              "         [3.3474058e-02, 0.0000000e+00, 0.0000000e+00, 2.3239497e-02,\n",
              "          1.3901936e-02, 2.0851741e-02, 0.0000000e+00, 0.0000000e+00,\n",
              "          7.6191938e-03, 1.6248610e-02, 0.0000000e+00, 4.7639798e-02,\n",
              "          0.0000000e+00, 0.0000000e+00, 2.6531804e-02, 1.8276537e-02,\n",
              "          4.3799128e-02, 0.0000000e+00, 0.0000000e+00, 2.3779026e-03,\n",
              "          2.2480687e-02, 1.0863047e-02, 4.2251475e-02, 3.6259713e-03,\n",
              "          0.0000000e+00, 1.8738210e-02, 3.4544587e-02, 0.0000000e+00,\n",
              "          3.3347502e-02, 0.0000000e+00, 4.0786184e-02, 4.7010683e-02],\n",
              "         [3.3474058e-02, 0.0000000e+00, 0.0000000e+00, 2.3239499e-02,\n",
              "          1.3901932e-02, 2.0851742e-02, 0.0000000e+00, 0.0000000e+00,\n",
              "          7.6191965e-03, 1.6248615e-02, 0.0000000e+00, 4.7639798e-02,\n",
              "          0.0000000e+00, 0.0000000e+00, 2.6531797e-02, 1.8276539e-02,\n",
              "          4.3799121e-02, 0.0000000e+00, 0.0000000e+00, 2.3779022e-03,\n",
              "          2.2480687e-02, 1.0863053e-02, 4.2251468e-02, 3.6259764e-03,\n",
              "          0.0000000e+00, 1.8738214e-02, 3.4544591e-02, 0.0000000e+00,\n",
              "          3.3347502e-02, 0.0000000e+00, 4.0786184e-02, 4.7010675e-02],\n",
              "         [3.3474065e-02, 0.0000000e+00, 0.0000000e+00, 2.3239497e-02,\n",
              "          1.3901932e-02, 2.0851735e-02, 0.0000000e+00, 0.0000000e+00,\n",
              "          7.6191886e-03, 1.6248602e-02, 0.0000000e+00, 4.7639795e-02,\n",
              "          0.0000000e+00, 0.0000000e+00, 2.6531804e-02, 1.8276537e-02,\n",
              "          4.3799125e-02, 0.0000000e+00, 0.0000000e+00, 2.3779057e-03,\n",
              "          2.2480685e-02, 1.0863051e-02, 4.2251464e-02, 3.6259759e-03,\n",
              "          0.0000000e+00, 1.8738210e-02, 3.4544580e-02, 0.0000000e+00,\n",
              "          3.3347499e-02, 0.0000000e+00, 4.0786192e-02, 4.7010675e-02]]],\n",
              "       dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
              " array([[0.09428476, 0.0062096 , 0.09018737, 0.07090468, 0.0905181 ,\n",
              "         0.07488595, 0.04111875, 0.03148964, 0.07038359, 0.08887433,\n",
              "         0.03693938, 0.0476398 , 0.02078506, 0.02553304, 0.06601496,\n",
              "         0.01827654, 0.04379913, 0.06528591, 0.        , 0.02801149,\n",
              "         0.0632726 , 0.06133521, 0.04225148, 0.05232302, 0.05823251,\n",
              "         0.12395434, 0.06127799, 0.01378333, 0.0333475 , 0.        ,\n",
              "         0.04078619, 0.08730216]], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLxl5v7AgCdl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "805f46c0-9f84-44e4-f8c8-ffcfdf5868eb"
      },
      "source": [
        "# Create 1-dimensional convolutional layer to model sequences\n",
        "inputs = tf.keras.layers.Input(shape = (1,),dtype = \"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = tf.keras.layers.Conv1D(filters = 32,kernel_size=5,activation = tf.keras.activations.relu)(x)\n",
        "x = tf.keras.layers.GlobalMaxPool1D()(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer\n",
        "outputs = tf.keras.layers.Dense(1,activation=tf.keras.activations.sigmoid)(x)\n",
        "model_5 = tf.keras.Model(inputs,outputs,name = \"model_5_Conv1D\")\n",
        "\n",
        "\n",
        "# Compile Conv1D model\n",
        "model_5.compile(loss = tf.keras.losses.binary_crossentropy,\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])\n",
        "\n",
        "model_5.summary()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 11, 32)            20512     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,300,545\n",
            "Trainable params: 1,300,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7wPvC1ihbX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e7005ef-96c1-47ce-f8e2-9c98e6f0fa82"
      },
      "source": [
        "# Fit the model\n",
        "model_5_history = model_5.fit(train_sentence,\n",
        "                              train_label,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentence, val_label),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"Conv1D\")])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20210528-110714\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 19ms/step - loss: 0.1447 - accuracy: 0.9517 - val_loss: 0.8586 - val_accuracy: 0.7717\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0765 - accuracy: 0.9727 - val_loss: 1.0092 - val_accuracy: 0.7651\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0609 - accuracy: 0.9772 - val_loss: 1.0916 - val_accuracy: 0.7612\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0559 - accuracy: 0.9774 - val_loss: 1.1531 - val_accuracy: 0.7625\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0495 - accuracy: 0.9794 - val_loss: 1.2190 - val_accuracy: 0.7612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d4BN0EriFXV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5e24b22-78e6-4f9c-8a6c-b75a78ad3917"
      },
      "source": [
        "# Make predictions with model_5\n",
        "model_5_pred_probs = model_5.predict(val_sentence)\n",
        "model_5_pred_probs[:10]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.2052975e-01],\n",
              "       [8.7060648e-01],\n",
              "       [9.9995458e-01],\n",
              "       [6.0723897e-02],\n",
              "       [1.4686242e-07],\n",
              "       [9.9714953e-01],\n",
              "       [8.9461374e-01],\n",
              "       [9.9992239e-01],\n",
              "       [9.9999917e-01],\n",
              "       [8.5533839e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W025GEEinUd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01e56139-432e-414b-d73c-f27eb2ee4d8a"
      },
      "source": [
        "# Convert model_5 prediction probabilities to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3JBlyKAipeA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad3639f4-4880-411f-a011-b5824a3b3948"
      },
      "source": [
        "# Calculate model_5 evaluation metrics \n",
        "model_5_results = calculate_results(y_true=val_label, \n",
        "                                    y_preds=model_5_preds)\n",
        "model_5_results"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.11548556430446,\n",
              " 'f1': 0.7597317731418467,\n",
              " 'precision': 0.761395918264994,\n",
              " 'recall': 0.7611548556430446}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-Ic4tRhiv08"
      },
      "source": [
        "#Model 6:TensorFlow Hub Pretrained Sentence Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUe9k8ScisG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9f7bf66-cdb8-4c8c-c58b-7dc09d0bc1c1"
      },
      "source": [
        "# Example of pretrained embedding with universal sentence encoder - https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")  # load Universal Sentence Encoder\n",
        "embed_samples = embed([\n",
        "                       sample_sentence,\n",
        "                       \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"\n",
        "                       ])\n",
        "print(embed_samples[0][:50])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[-0.02225108  0.00158148  0.06297328 -0.01693677  0.04321926  0.07595062\n",
            "  0.02784285  0.03860461  0.00998433 -0.00585812  0.02477576 -0.01942308\n",
            "  0.04693455  0.08285864  0.0721465  -0.05024614  0.03174825 -0.04299723\n",
            "  0.03192997 -0.06307844 -0.02894014  0.03847192  0.05160181  0.03639915\n",
            " -0.0033893  -0.06244716 -0.02321451  0.01089256 -0.05442338 -0.04424192\n",
            " -0.00513377  0.04550229 -0.02244516 -0.00698457 -0.02018636 -0.07282844\n",
            "  0.01419754  0.02534257  0.01080804 -0.05853831  0.00585868  0.0051272\n",
            " -0.05329772  0.04366577 -0.10668346 -0.03303329 -0.03203182 -0.02387945\n",
            "  0.00843923  0.02884514], shape=(50,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP8Alwcnjbf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b3845a1-44b0-432a-d6da-ee01a9c7efa9"
      },
      "source": [
        "# Each sentence has been encoded into a 512 dimension vector\n",
        "embed_samples[0].shape"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrQHKw15jhUV"
      },
      "source": [
        "# We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
        "sentence_encoded_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape = [],\n",
        "                                        dtype = \"string\",\n",
        "                                        trainable = False,\n",
        "                                        name = \"USE\")"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOB-MsmIkIVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343038d8-5f01-430b-aca7-c73329cb7889"
      },
      "source": [
        "# Create model using the Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "                  sentence_encoded_layer,# take in sentences and then encode them into an embedding\n",
        "                  tf.keras.layers.Dense(64,activation = tf.keras.activations.relu),\n",
        "                  tf.keras.layers.Dense(1,activation = tf.keras.activations.sigmoid)\n",
        "\n",
        "],name = \"model_6_use\")\n",
        "\n",
        "model_6.compile(loss = tf.keras.losses.binary_crossentropy,\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])\n",
        "model_6.summary()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6_use\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_IGlVwykxRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d897120-9116-40e5-cf7a-22f8a28ffb9d"
      },
      "source": [
        "# Train a classifier on top of pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentence,\n",
        "                              train_label,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentence, val_label),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"tf_hub_sentence_encoder\")])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20210528-110752\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 23ms/step - loss: 0.5024 - accuracy: 0.7808 - val_loss: 0.4482 - val_accuracy: 0.7966\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.4138 - accuracy: 0.8132 - val_loss: 0.4391 - val_accuracy: 0.8084\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.4004 - accuracy: 0.8231 - val_loss: 0.4354 - val_accuracy: 0.8058\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3931 - accuracy: 0.8267 - val_loss: 0.4319 - val_accuracy: 0.8110\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3858 - accuracy: 0.8307 - val_loss: 0.4269 - val_accuracy: 0.8150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46zvKwIIk6Lc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "582fda53-332b-4eb1-bf97-459a2ce0a430"
      },
      "source": [
        "# Make predictions with USE TF Hub model\n",
        "model_6_pred_probs = model_6.predict(val_sentence)\n",
        "model_6_pred_probs[:10]"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.23230161],\n",
              "       [0.8325033 ],\n",
              "       [0.99290574],\n",
              "       [0.20465289],\n",
              "       [0.7772518 ],\n",
              "       [0.7761996 ],\n",
              "       [0.9880447 ],\n",
              "       [0.98427653],\n",
              "       [0.946655  ],\n",
              "       [0.10482991]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMRWZlRolWzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "820922b7-819d-4db5-aa95-b90a97fa87e4"
      },
      "source": [
        "\n",
        "# Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqyjT-IllfHX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c1d9f4-56c7-4db3-9178-c8f8e8db1f67"
      },
      "source": [
        "\n",
        "# Calculate model 6 performance metrics\n",
        "model_6_results = calculate_results(val_label, model_6_preds)\n",
        "model_6_results"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.49606299212599,\n",
              " 'f1': 0.8143707124948604,\n",
              " 'precision': 0.8150356086855799,\n",
              " 'recall': 0.8149606299212598}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bWr6N_ZBqFG"
      },
      "source": [
        "# Model 7: TensorFlow Hub Pretrained Sentence Encoder 10% of the training data\n",
        "\n",
        "Transfer learning really helps when you don't have a large dataset\n",
        "\n",
        "To see how our model performs on a smaller dataset let's replicate `model_6` except we will train it on 10% of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2Gg6ro2lg2C"
      },
      "source": [
        "### NOTE: Making splits like this will lead to data leakage ###\n",
        "### (some of the training examples in the validation set) ###\n",
        "\n",
        "### WRONG WAY TO MAKE SPLITS (train_df_shuffled has already been split) ###\n",
        "# # Create subsets of 10% of the training data\n",
        "# train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
        "# train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
        "# train_labels_10_percent = train_10_percent[\"target\"].to_list()\n",
        "# len(train_sentences_10_percent), len(train_labels_10_percent)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeoIG2ezGkbD"
      },
      "source": [
        "# One kind of correct way (there are more) to make data subset\n",
        "# (split the already split train_sentences/train_labels)\n",
        "import numpy as np\n",
        "train_sentence_90_percent,train_sentences_10_percent,train_labels_90_percent,train_labels_10_sentences = train_test_split(np.array(train_sentence),\n",
        "                                                                                                                          train_label,\n",
        "                                                                                                                          test_size = 0.1,\n",
        "                                                                                                                          random_state = 42)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUQR-lIMHKlk",
        "outputId": "9bcca157-e5ef-4b67-e476-3afd8605de5a"
      },
      "source": [
        "# Check length of 10 percent datasets\n",
        "print(f\"Total training examples: {len(train_sentence)}\")\n",
        "print(f\"Length of 10% training examples: {len(train_sentences_10_percent)}\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total training examples: 6851\n",
            "Length of 10% training examples: 686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXz8dtTLIgpH",
        "outputId": "d41d40a9-5fcc-4aa8-b7bd-e198b72979d7"
      },
      "source": [
        "# Check the number of targets in our subset of data \n",
        "# (this should be close to the distribution of labels in the original train_labels)\n",
        "pd.Series(train_labels_10_sentences).value_counts()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    415\n",
              "1    271\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJCr0gUTIlpr",
        "outputId": "21a0623f-cf12-47b2-cf6c-d799b21ca93f"
      },
      "source": [
        "# Clone model_6 but reset weights\n",
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "# Compile the model\n",
        "model_7.compile(loss = tf.keras.losses.binary_crossentropy,\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])\n",
        "model_7.summary()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6_use\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaNCKu9cKKXy",
        "outputId": "ccd3fdef-d962-49d3-c75a-b5d52aee843e"
      },
      "source": [
        "# Fit the model to 10% of the training data\n",
        "model_7.history = model_7.fit(x = train_sentences_10_percent,\n",
        "                              y = train_labels_10_sentences,\n",
        "                              epochs = 5,\n",
        "                              validation_data = (val_sentence,val_label),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"10_percent_tf_hub_sentence_encoder\")])"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/10_percent_tf_hub_sentence_encoder/20210528-110813\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 4s 113ms/step - loss: 0.6661 - accuracy: 0.6983 - val_loss: 0.6415 - val_accuracy: 0.7205\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.5905 - accuracy: 0.7959 - val_loss: 0.5820 - val_accuracy: 0.7546\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.5157 - accuracy: 0.8207 - val_loss: 0.5317 - val_accuracy: 0.7638\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.4538 - accuracy: 0.8397 - val_loss: 0.5020 - val_accuracy: 0.7730\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.4115 - accuracy: 0.8426 - val_loss: 0.4894 - val_accuracy: 0.7795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tu33wJx1Ll4g",
        "outputId": "822ff6b3-a397-4c06-c6c4-01fa209c3201"
      },
      "source": [
        "# Make predictions with the model trained on 10% of the data\n",
        "model_7_pred_probs = model_7.predict(val_sentence)\n",
        "model_7_pred_probs[:10]"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.26446113],\n",
              "       [0.7853607 ],\n",
              "       [0.90102226],\n",
              "       [0.3251526 ],\n",
              "       [0.5715442 ],\n",
              "       [0.84769714],\n",
              "       [0.82241964],\n",
              "       [0.85993946],\n",
              "       [0.8254788 ],\n",
              "       [0.11793774]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BTRlG8tLptU",
        "outputId": "9c3ac7b3-bf57-47dc-dca8-b987f53abbb3"
      },
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YivlQyMILw4y",
        "outputId": "c2a5f539-48c0-4236-8022-3677fa1cea57"
      },
      "source": [
        "# Calculate model results\n",
        "model_7_results = calculate_results(val_label, model_7_preds)\n",
        "model_7_results"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.95275590551181,\n",
              " 'f1': 0.7765763088894867,\n",
              " 'precision': 0.7837012857570019,\n",
              " 'recall': 0.7795275590551181}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SwejAEEL4ja"
      },
      "source": [
        "# Comparing the performance of each of our models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "V4YTDJ0fLyqM",
        "outputId": "b80802e9-dca3-4909-c2d9-4c3fcaeababc"
      },
      "source": [
        "# Combine model results into a DataFrame\n",
        "\n",
        "all_model_results = pd.DataFrame({\"baseline\":baseline_results,\n",
        "                                  \"simple_dense\":model_1_results,\n",
        "                                  \"lstm\":model_2_results,\n",
        "                                  \"gru\":model_3_results,\n",
        "                                  \"bidirectional\":model_4_results,\n",
        "                                  \"conv1d\":model_5_results,\n",
        "                                  \"tf_hub_sentence_encode\":model_6_results,\n",
        "                                  \"tf_hub_10_percent_data\":model_7_results\n",
        "                                \n",
        "})\n",
        "\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>79.265092</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>77.690289</td>\n",
              "      <td>0.778187</td>\n",
              "      <td>0.776903</td>\n",
              "      <td>0.775124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>76.902887</td>\n",
              "      <td>0.771739</td>\n",
              "      <td>0.769029</td>\n",
              "      <td>0.766386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>77.821522</td>\n",
              "      <td>0.780752</td>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.775881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>77.427822</td>\n",
              "      <td>0.777506</td>\n",
              "      <td>0.774278</td>\n",
              "      <td>0.771552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>76.115486</td>\n",
              "      <td>0.761396</td>\n",
              "      <td>0.761155</td>\n",
              "      <td>0.759732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_sentence_encode</th>\n",
              "      <td>81.496063</td>\n",
              "      <td>0.815036</td>\n",
              "      <td>0.814961</td>\n",
              "      <td>0.814371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_10_percent_data</th>\n",
              "      <td>77.952756</td>\n",
              "      <td>0.783701</td>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.776576</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         accuracy  precision    recall        f1\n",
              "baseline                79.265092   0.811139  0.792651  0.786219\n",
              "simple_dense            77.690289   0.778187  0.776903  0.775124\n",
              "lstm                    76.902887   0.771739  0.769029  0.766386\n",
              "gru                     77.821522   0.780752  0.778215  0.775881\n",
              "bidirectional           77.427822   0.777506  0.774278  0.771552\n",
              "conv1d                  76.115486   0.761396  0.761155  0.759732\n",
              "tf_hub_sentence_encode  81.496063   0.815036  0.814961  0.814371\n",
              "tf_hub_10_percent_data  77.952756   0.783701  0.779528  0.776576"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsPTEE61NPpE"
      },
      "source": [
        "# Reduce the accuracy to same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "i1aPT6YRNGHs",
        "outputId": "4153214c-71b3-4d21-89e4-2cfb6d0f1873"
      },
      "source": [
        " #Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "UpqJqQYFNKe-",
        "outputId": "8111e870-f712-4e8d-8711-91c36841d46a"
      },
      "source": [
        "# Sort model results by f1-score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgmn_7lkNWVu"
      },
      "source": [
        "# # View tensorboard logs of transfer learning modelling experiments (should be 4 models)\n",
        "#!tensorboard dev upload --logdir ./model_logs \\\n",
        " #--name \"NLP moddelling experiment\"\\\n",
        " #--description \"A series of different NLP modellings experiments with various models\"\\\n",
        " #--one_shot # exits the uploader when upload has finished"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXOpx-h9OPUv"
      },
      "source": [
        "# If you need to remove previous experiments, you can do so using the following command\n",
        "# !tensorboard dev delete --experiment_id EXPERIMENT_ID_TO_DELETE"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDlGEsmhPZPT"
      },
      "source": [
        "#Saving and loading a trained model\n",
        "\n",
        "There are two main ways of saving a model in TensorFlow:\n",
        "\n",
        "1. The HDF5 format.\n",
        "2. The SavedModel format (default)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82-hpNM9O_zw"
      },
      "source": [
        "# Save TF Hub Sentence Encoder model to HDF5 format\n",
        "model_6.save(\"model_6.h5\")"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00PxhQ2rPqQ4"
      },
      "source": [
        "# Load model with custom Hub Layer (required with HDF5 format)\n",
        "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\", \n",
        "                                            custom_objects={\"KerasLayer\": hub.KerasLayer})"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFprsnIyP7Hs",
        "outputId": "825ce8c7-a24c-468b-c590-4598759fe216"
      },
      "source": [
        "# How does our loaded model perform?\n",
        "loaded_model_6.evaluate(val_sentence, val_label)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 8ms/step - loss: 0.4269 - accuracy: 0.8150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4269331395626068, 0.8149606585502625]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAzlrrPVQXJO"
      },
      "source": [
        "Now let's save to the save model format\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woz_azazQMfX",
        "outputId": "d0558740-cf8b-461e-878a-e0496a4a95af"
      },
      "source": [
        "# Save TF Hub Sentence Encoder model to SavedModel format (default)\n",
        "model_6.save(\"model_6_SavedModel_format\")"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb6dqSlFQiVk"
      },
      "source": [
        "# Load TF Hub Sentence Encoder SavedModel\n",
        "loaded_model_6_SavedModel = tf.keras.models.load_model(\"model_6_SavedModel_format\")"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7QTHJhBQl8p",
        "outputId": "868ec484-bf65-43d3-93eb-c1364de81f17"
      },
      "source": [
        "# Evaluate loaded SavedModel format\n",
        "loaded_model_6_SavedModel.evaluate(val_sentence, val_label)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 9ms/step - loss: 0.4269 - accuracy: 0.8150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4269331395626068, 0.8149606585502625]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r_4RNWjQzBJ"
      },
      "source": [
        "# Finding the most wrong examples\n",
        "\n",
        "* If our model is still isn't perfect what examples is it getting wrong\n",
        "* And of these wrong examples which one is getting  most wrong(those will prediction probabilities closest to opposite class)\n",
        "\n",
        "For eg if a sample should have a label of 0 but our model predict probability of 0.999(which is really close to 1) and vice versa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8SCvOpyS5C5",
        "outputId": "357a1b77-d8be-42fc-99aa-abc6fe9ff6e9"
      },
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
        "!unzip 08_model_6_USE_feature_extractor.zip"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-28 11:08:52--  https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.137.128, 142.250.101.128, 142.250.141.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.137.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 960779165 (916M) [application/zip]\n",
            "Saving to: ‘08_model_6_USE_feature_extractor.zip’\n",
            "\n",
            "08_model_6_USE_feat 100%[===================>] 916.27M  43.7MB/s    in 13s     \n",
            "\n",
            "2021-05-28 11:09:06 (69.1 MB/s) - ‘08_model_6_USE_feature_extractor.zip’ saved [960779165/960779165]\n",
            "\n",
            "Archive:  08_model_6_USE_feature_extractor.zip\n",
            "   creating: 08_model_6_USE_feature_extractor/\n",
            "   creating: 08_model_6_USE_feature_extractor/assets/\n",
            "   creating: 08_model_6_USE_feature_extractor/variables/\n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.data-00000-of-00001  \n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.index  \n",
            "  inflating: 08_model_6_USE_feature_extractor/saved_model.pb  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rLYoETFTRUF",
        "outputId": "132324d4-8881-4182-8378-e4cb868fbdb1"
      },
      "source": [
        "model_06_pretrained = tf.keras.models.load_model(\"08_model_6_USE_feature_extractor\")\n",
        "model_06_pretrained.evaluate(val_sentence,val_label)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 9ms/step - loss: 0.4272 - accuracy: 0.8163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42723122239112854, 0.8162729740142822]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xltVEF3QTyKn",
        "outputId": "e176f9a1-86d8-4810-d6eb-0a69605058cd"
      },
      "source": [
        "model_6_pretrained_pred_probs = model_06_pretrained.predict(val_sentence)\n",
        "model_6_pretrained_pred_probs = tf.squeeze(model_6_pretrained_pred_probs)\n",
        "model_6_pretrained_pred_probs[:10]"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([0.15975739, 0.74716204, 0.98874855, 0.19622947, 0.7078078 ,\n",
              "       0.7096749 , 0.98190695, 0.9810662 , 0.94574374, 0.08504029],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "nycEabi8Qp8m",
        "outputId": "a22a7aa8-f143-4c10-89a3-ecf49b797d2b"
      },
      "source": [
        "# Create dataframe with validation sentences and best performing model predictions\n",
        "val_df = pd.DataFrame({\"text\": val_sentence,\n",
        "                       \"target\": val_label,\n",
        "                       \"pred\":model_6_preds,\n",
        "                       \"pred_prob\": tf.squeeze(model_6_pred_probs)})\n",
        "val_df.head()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.832503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.992906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.204653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.777252</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target  pred  pred_prob\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.232302\n",
              "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.832503\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.992906\n",
              "3  @camilacabello97 Internally and externally scr...       1   0.0   0.204653\n",
              "4  Radiation emergency #preparedness starts with ...       1   1.0   0.777252"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "KAh8mP-WSKS0",
        "outputId": "f24dcc79-a2a3-4047-8497-3359270c2c4f"
      },
      "source": [
        "# Find the wrong predictions and sort by prediction probabilities\n",
        "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\",ascending = False)\n",
        "most_wrong[:10]"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.935803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.918075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.894729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.880940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.863494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Ten...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.845735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.845541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.844725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.832503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>The Sound of Arson</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.829086</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  target  pred  pred_prob\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   0.935803\n",
              "759  FedEx will no longer transport bioterror patho...       0   1.0   0.918075\n",
              "628  @noah_anyname That's where the concentration c...       0   1.0   0.894729\n",
              "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   0.880940\n",
              "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   0.863494\n",
              "698  åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Ten...       0   1.0   0.845735\n",
              "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   0.845541\n",
              "251  @AshGhebranious civil rights continued in the ...       0   1.0   0.844725\n",
              "1    FedEx no longer to transport bioterror germs i...       0   1.0   0.832503\n",
              "144                                 The Sound of Arson       0   1.0   0.829086"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrktWcA-vxdn"
      },
      "source": [
        "A reminder:\n",
        "\n",
        "* 0 = Not a real diaster Tweet\n",
        "* 1 = Real diaster Tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_8ouVXauF0A",
        "outputId": "336a079b-0f0b-4173-d633-4883b64e1704"
      },
      "source": [
        "# Check the false positives (model predicted 1 when should've been 0)\n",
        "for row in most_wrong[:10].itertuples(): # loop through the top 10 rows (change the index to view different rows)\n",
        "  _,text,target,pred,prob = row\n",
        "  print(f\"Target:{target},Pred:{int(pred)},Prob:{prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")\n",
        "\n",
        "       \n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target:0,Pred:1,Prob:0.9358030557632446\n",
            "Text:\n",
            "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
            "\n",
            "----\n",
            "\n",
            "Target:0,Pred:1,Prob:0.9180748462677002\n",
            "Text:\n",
            "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
            "\n",
            "----\n",
            "\n",
            "Target:0,Pred:1,Prob:0.8947287201881409\n",
            "Text:\n",
            "@noah_anyname That's where the concentration camps and mass murder come in. \n",
            " \n",
            "EVERY. FUCKING. TIME.\n",
            "\n",
            "----\n",
            "\n",
            "Target:0,Pred:1,Prob:0.8809401392936707\n",
            "Text:\n",
            "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
            "\n",
            "----\n",
            "\n",
            "Target:0,Pred:1,Prob:0.8634936213493347\n",
            "Text:\n",
            "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
            "\n",
            "----\n",
            "\n",
            "Target:0,Pred:1,Prob:0.8457349538803101\n",
            "Text:\n",
            "åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Tent Collapse Story: Correction: Tent Collapse story åÈ http://t.co/fDJUYvZMrv @wizkidayo\n",
            "\n",
            "----\n",
            "\n",
            "Target:0,Pred:1,Prob:0.8455408215522766\n",
            "Text:\n",
            "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
            "\n",
            "----\n",
            "\n",
            "Target:0,Pred:1,Prob:0.8447249531745911\n",
            "Text:\n",
            "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
            "\n",
            "----\n",
            "\n",
            "Target:0,Pred:1,Prob:0.8325033187866211\n",
            "Text:\n",
            "FedEx no longer to transport bioterror germs in wake of anthrax lab mishaps http://t.co/qZQc8WWwcN via @usatoday\n",
            "\n",
            "----\n",
            "\n",
            "Target:0,Pred:1,Prob:0.8290859460830688\n",
            "Text:\n",
            "The Sound of Arson\n",
            "\n",
            "----\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQBcrz3zx_vY"
      },
      "source": [
        "# Making predictions on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v1qygfGwphE"
      },
      "source": [
        "# Turn Tweet into string\n",
        "daniels_tweet = \"Life like an ensemble: take the best choices from others and make your own\""
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkNGkVHFyXAb"
      },
      "source": [
        "def predict_on_sentence(model, sentence):\n",
        "  \"\"\"\n",
        "  Uses model to make a prediction on sentence.\n",
        "\n",
        "  Returns the sentence, the predicted label and the prediction probability.\n",
        "  \"\"\"\n",
        "  pred_prob = model.predict([sentence])\n",
        "  pred_label = tf.squeeze(tf.round(pred_prob)).numpy()\n",
        "  print(f\"Pred: {pred_label}\", \"(real disaster)\" if pred_label > 0 else \"(not real disaster)\", f\"Prob: {pred_prob[0][0]}\")\n",
        "  print(f\"Text:\\n{sentence}\")"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy7kmIR_0De4",
        "outputId": "a7c19578-c9de-4b30-8d8f-6f820043faeb"
      },
      "source": [
        "# Make a prediction on Tweet from the wild\n",
        "predict_on_sentence(model=model_6, # use the USE model\n",
        "                    sentence=daniels_tweet)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred: 0.0 (not real disaster) Prob: 0.05669981613755226\n",
            "Text:\n",
            "Life like an ensemble: take the best choices from others and make your own\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsOEzuEh0Fxp"
      },
      "source": [
        "disaster = \" A two-storey building collapsed in Makhdumpur, Jehanabad. No casualties reported so far. \""
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBYk3mMz0a5o",
        "outputId": "d829ebfa-64db-49f3-ab6f-5aa34061f60c"
      },
      "source": [
        "predict_on_sentence(model=model_6, # use the USE model\n",
        "                    sentence=disaster)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred: 1.0 (real disaster) Prob: 0.9883749485015869\n",
            "Text:\n",
            " A two-storey building collapsed in Makhdumpur, Jehanabad. No casualties reported so far. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CSB263j1JgZ"
      },
      "source": [
        "# The speed/score tradeoff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnxZOvrJ0fEP"
      },
      "source": [
        "# Calculate the time of predictions\n",
        "import time\n",
        "def pred_timer(model, samples):\n",
        "  \"\"\"\n",
        "  Times how long a model takes to make predictions on samples.\n",
        "  \n",
        "  Args:\n",
        "  ----\n",
        "  model = a trained model\n",
        "  sample = a list of samples\n",
        "\n",
        "  Returns:\n",
        "  ----\n",
        "  total_time = total elapsed time for model to make predictions on samples\n",
        "  time_per_pred = time in seconds per single sample\n",
        "  \"\"\"\n",
        "  start_time = time.perf_counter() # get start time\n",
        "  model.predict(samples) # make predictions\n",
        "  end_time = time.perf_counter() # get finish time\n",
        "  total_time = end_time-start_time # calculate how long predictions took to make\n",
        "  time_per_pred = total_time/len(val_sentence) # find prediction time per sample\n",
        "  return total_time, time_per_pred"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk0oSOCq1N7x",
        "outputId": "6d3cf318-f54e-4102-97fd-55802594cab9"
      },
      "source": [
        "# Calculate TF Hub Sentence Encoder prediction times\n",
        "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model_6, val_sentence)\n",
        "model_6_total_pred_time, model_6_time_per_pred"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.2222102350001478, 0.00029161448162749054)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JdK4YiH1aun",
        "outputId": "ce32b2f0-fafd-470f-d4a8-0b8856d3113e"
      },
      "source": [
        " #Calculate Naive Bayes prediction times\n",
        "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentence)\n",
        "baseline_total_pred_time, baseline_time_per_pred"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.015493912999772874, 2.033321915980692e-05)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "vMgAZG8k1oO3",
        "outputId": "a8185fcc-a911-4a12-b733-08eead1df25b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label=\"baseline\")\n",
        "plt.scatter(model_6_time_per_pred, model_6_results[\"f1\"], label=\"tf_hub_sentence_encoder\")\n",
        "plt.legend()\n",
        "plt.title(\"F1-score versus time per prediction\")\n",
        "plt.xlabel(\"Time per prediction\")\n",
        "plt.ylabel(\"F1-Score\");"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8eQLV5k1t0B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}